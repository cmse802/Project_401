{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow vs Large Datasets\n",
    "\n",
    "By: Hannah Toth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Collage of different TV networks\" src=\"https://miro.medium.com/max/3840/1*zAv-pZ2lW6e1XXygD9UaPQ.jpeg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "In this project, my main goal is to optimize tensorflow's machine leraning capabilities with larger datasets. The reason I want to focus on this specifically is because in my final group project for CMSE 202 we were trying to predict classes of specific galaxies based on provided images. The dataset we were using had over 10,000 entires and to use the machine learning techniques in order to create a model took almost an hour to run with the entire dataset. Due to this, we had to minimize the amount of data we were using, which led to a more inaccurate model. As for the topic that I will be using with tensorflow this time, I was unable to decide on one for quite awhile. However, I was discussing it with my mom and she actually gave me a great idea about what I could do. My mom is a National Broadcast Negotiator, which means that she negotiates national broadcast rates with cable networks so she can purchase airtime for her employer. She works with Neilson Media Research who predicts the trends of specific networks in order to determine optimal airtime placement. Neilson uses different forecasting algorithms to make their predictions, so I was planning to use those as one of the bench marking tools to determine if my method optimization was sucessful. My mom also sometimes decides to make the predictions by hand, which can be a lengthy process when going over years of data. I want to create a model that can help predict the trends of networks given years of data in a timely manner. I also want to look into tensorflow's capabilities to see if I could maybe include optimized placement for purchases in my model. I plan to create my models in jupyter notebook before moving to the HPCC as well as having time studies to determine the average run time of the model with no optimization. I'm hoping that in making this model, I can help my mom a bit by providing a program that can create accurate and quick predictions so that she won't have to do them by hand anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule\n",
    "\n",
    "* Thursday February 11 - Project Proposal Milestone Due\n",
    "* Week of February 15 - Get the datasets from Neilson, and look over them\n",
    "* Week of February 22 - Determine what my model is going to predict in the end (trends or trends & optimal placement)\n",
    "* Week of March 1 - Clean up the datasets\n",
    "* Week of March 8 - Create models on jupyter\n",
    "* Week of March 15 - Finish up creation of models (determine accuracy)/Start time trials\n",
    "* Week of March 21 - Finish time trials/Start upload onto HPCC\n",
    "* Week of March 22 - Finish everything that needs to be done on the HPCC\n",
    "* Thursday March 25 - Project Part 1 Due\n",
    "* Week of March 28 - Get benchmark times from Neilson predictors/my mom's time when making predictions by hand\n",
    "* Week of March 29 - Begin optimization methods on the models\n",
    "* Week of April 5 - Finish any optimization that is left/Start time trials\n",
    "* Week of April 12 - Finish any time trials that are left/Compare to benchmark\n",
    "* Thursday April 15 - Final Project due"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Software Exploration\n",
    "\n",
    "For this project I am planning to use tensorflow's machine learning methods in order to create my prediction model. I am using this software because I have experience with making models using it due to previous CMSE classes that I have taken. The tensorflow website (https://www.tensorflow.org/resources/learn-ml/basics-of-machine-learning) provides various resources that I can utilize during this project. It has sample code for specific functions as well as basic information on machine learning. The datasets that I plan to use with this project, I will be receiving this weekend as I want to look over everything with my mom so I can determine which datasets I plan to use. To start, I plan to make sure that my models run correctly by using jupyter, and then transporting that working code onto the HPCC. Also, as I move everything onto the HPCC, I can make a file that contains the directions to run everything as I am adding it/figuring it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Benchmark and Optimization\n",
    "\n",
    "Currently I plan to have four different times to compare to one another. Two of the time benchmarks are not a result of the model I will be creating. The first benchmark is from the predictor algortihms that Neilson provides. Since I do not have access to this program, I will not be able to run it on my own machine/the HPCC, and I will have to have my mom run it for me and provide me with the time. The second benchmark will be how long it takes for my mom to complete the predictions by hand. The last two time variables will come from my code with and without optimization. Once I have made the model without optimization, I will perform time trials to determine the average runtime. If this time is smaller than either of the two benchmarks, I can consider my model a success. I believe the model without optimization will be quicker than the hand prediction, but I don't believe it will be quicker than the Neilson predictions. Therefore, I will also conduct time trials on the optimized model. If the average of these trials is quicker than the two bench marks, it can be considered a success (assuming the predictions from the model are actually accurate). It the optimized model is slower than either of the two benchmarks, or the unoptimized code, than the optimization has failed. In order to optimize tensorflow, I researched what could be done to have it run in parallel, and it appears that there are functions within tensorflow that distribute the work across multiple GPUS (https://www.tensorflow.org/guide/distributed_training)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
